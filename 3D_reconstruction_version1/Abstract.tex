\begin{abstract}
Extracting buildings from remote sensing images plays an important role in urban applications (e.g., urban planning and digital city). However, this task is quite difficult due to great diversity of buildings and similarities between buildings and other categories. Recent approaches have attempted to harness the capabilities of deep learning techniques for building extraction. In this paper, we propose a robust system which can extract buildings from large-scale remote sensing images and build 3D models for extracted building areas. Learning low-level information of images becomes as important as learning high-level semantic information since buildings in remote images possess various scales and aspect ratios. So we propose a novel hierarchically fused fully convolutional network (HF-FCN). The proposed network generates the final prediction results in a fusion manner through making full use of the information extracted from each layer. Using modified VGG16 network, our method achieves state-of-the-art performance on several available remote sensing image datasets. In addition, we add the corresponding Digital Surface Model (DSM) map and extract the segmented building area to generate the point cloud of its roof. Then, based on the generated point cloud, the 3D modeling of buildings is implemented.
\end{abstract}
% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
building extraction, Hierarchically Fused Fully Convolutional Network (HF-FCN), 3D city modelling
\end{IEEEkeywords}