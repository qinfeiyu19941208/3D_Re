\begin{abstract}
Extracting buildings from remote sensing images plays an important role in urban applications (e.g., urban planning and digital city). However, this task is quite difficult due to great diversity of buildings and similarities between buildings and other categories. Recent approaches have attempted to harness the capabilities of deep learning techniques for building extraction. In this paper, we propose a robust system which can extract buildings from large-scale remote sensing images and build 3D models for extracted building areas. Learning low-level appearance information and high-level semantic information are equally important since buildings in remote images possess various scales and aspect ratios. In order to make full use of the information extracted from each layer, we propose a novel hierarchically fused fully convolutional network (HF-FCN) which generates the final prediction results in a fusion manner. Using modified VGG16 network, our method achieves state-of-the-art performance on several available remote sensing image datasets. In addition, we add the corresponding Digital Surface Model (DSM) map and combine the segmented building area to generate the point cloud of rooftops. Then, based on the generated point cloud, the 3D modeling of buildings is implemented.
\end{abstract}
% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
building extraction, Hierarchically Fused Fully Convolutional Network (HF-FCN), 3D city modelling
\end{IEEEkeywords}
