\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:noronha2001detection}
\citation{IEEEexample:nosrati2009novel}
\citation{IEEEexample:izadi2012three}
\citation{IEEEexample:wang2015efficient}
\citation{IEEEexample:cote2013automatic}
\citation{IEEEexample:peng2005improved}
\citation{IEEEexample:sirmacek2009urban}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:zhao2017contextually}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:liu2017dense}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:kampffmeyer2017urban}
\citation{IEEEexample:he2017multi}
\citation{IEEEexample:Long_2015_CVPR}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{I}{1}{Introduction\relax }{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of remote sensing patches with different kinds of challenges. (a) Shadow occlusion in green frame. (b) Low inter-class differences. (c) High intra class variance. (d) A lot of tiny buildings close to each other.}}{1}{figure.1}}
\newlabel{fig:intro}{{1}{1}{Examples of remote sensing patches with different kinds of challenges. (a) Shadow occlusion in green frame. (b) Low inter-class differences. (c) High intra class variance. (d) A lot of tiny buildings close to each other}{figure.1}{}}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:noronha2001detection}
\citation{IEEEexample:nosrati2009novel}
\citation{IEEEexample:izadi2012three}
\citation{IEEEexample:wang2015efficient}
\citation{IEEEexample:cote2013automatic}
\citation{IEEEexample:peng2005improved}
\citation{IEEEexample:sirmacek2009urban}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:he2017multi}
\citation{IEEEexample:zhao2017contextually}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}}
\newlabel{Sec:RelatedWork}{{II}{2}{Related Work\relax }{section.2}{}}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:liu2017dense}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:kampffmeyer2017urban}
\citation{IEEEexample:hoffman2016learning}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:vemulapalli2016gaussian}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:he2016deep}
\citation{IEEEexample:szegedy2015going}
\citation{IEEEexample:szegedy2016rethinking}
\citation{IEEEexample:szegedy2017inception}
\citation{IEEEexample:xie2017aggregated}
\citation{IEEEexample:zhao2017contextually}
\citation{IEEEexample:he2016deep}
\citation{IEEEexample:zuo2016hf}
\citation{IEEEexample:zuo2016hf}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:lin2017feature}
\@writefile{toc}{\contentsline {section}{\numberline {III}Hierarchically Fused Fully Convolutional Network}{3}{section.3}}
\newlabel{Sec:HF-FCN}{{III}{3}{Hierarchically Fused Fully Convolutional Network\relax }{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The first line shows the overview of our network. The second row shows the details of two kinds of fusion operation. One is a case where the input is not equal to the output and the other is the input equal to the output. Fk means the feature maps come from the kth layer. m for number of feature maps. n said the n times of up sampling.}}{4}{figure.2}}
\newlabel{fig:Fusion-Operation}{{2}{4}{The first line shows the overview of our network. The second row shows the details of two kinds of fusion operation. One is a case where the input is not equal to the output and the other is the input equal to the output. Fk means the feature maps come from the kth layer. m for number of feature maps. n said the n times of up sampling}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Network Architecture}{4}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A diagram of convolution and transposed convolution. The traditional convolution and transposed convolution are shown in the left and right column, respectively. The input of convolution is ${4\times 4}$, the output is ${2\times 2}$ and the kernel is ${3\times 3}$. And the transposed convolution is the opposite.}}{4}{figure.3}}
\newlabel{fig:Deconv}{{3}{4}{A diagram of convolution and transposed convolution. The traditional convolution and transposed convolution are shown in the left and right column, respectively. The input of convolution is ${4\times 4}$, the output is ${2\times 2}$ and the kernel is ${3\times 3}$. And the transposed convolution is the opposite}{figure.3}{}}
\newlabel{fusion_1}{{1}{4}{Network Architecture\relax }{equation.3.1}{}}
\newlabel{Conv}{{2}{4}{Network Architecture\relax }{equation.3.2}{}}
\newlabel{Conv_matrix}{{3}{4}{Network Architecture\relax }{equation.3.3}{}}
\newlabel{Conv_matrix}{{4}{5}{Network Architecture\relax }{equation.3.4}{}}
\newlabel{fature_selection}{{5}{5}{Network Architecture\relax }{equation.3.5}{}}
\newlabel{Sigmoid}{{6}{5}{Network Architecture\relax }{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Network Training}{5}{subsection.3.2}}
\newlabel{loss}{{7}{5}{Network Training\relax }{equation.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{5}{section.4}}
\newlabel{Sec:exp}{{IV}{5}{Experiments\relax }{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sample patches on the three datasets (a) Massachusetts dataset (b) Vaihingen dataset (c) Potsdam dataset}}{5}{figure.4}}
\newlabel{fig:dataset_sample}{{4}{5}{Sample patches on the three datasets (a) Massachusetts dataset (b) Vaihingen dataset (c) Potsdam dataset\relax }{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Dataset Description}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0a}Massachusetts dataset}{5}{paragraph.4.1.0.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0b}Vaihingen dataset}{5}{paragraph.4.1.0.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0c}Potsdam dataset}{5}{paragraph.4.1.0.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Training Settings}{5}{subsection.4.2}}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:ronneberger2015u}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Composition of dataset}}{6}{table.1}}
\newlabel{table:dataset-composition}{{I}{6}{Composition of dataset\relax }{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Parameters for Network Training}}{6}{table.2}}
\newlabel{table:Train-Parameter}{{II}{6}{Parameters for Network Training\relax }{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Evaluation Metrics}{6}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces HF-FCN variants. The feature maps generated from final group are fused into a coarse result, which is HF-FCN16s. The variant called HF-FCN8s concatenates the feature maps from the last 2 groups with the same fusion operation, and so on.}}{6}{figure.5}}
\newlabel{fig:Variants}{{5}{6}{HF-FCN variants. The feature maps generated from final group are fused into a coarse result, which is HF-FCN16s. The variant called HF-FCN8s concatenates the feature maps from the last 2 groups with the same fusion operation, and so on}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Discussion}{6}{section.5}}
\newlabel{Sec:Res}{{V}{6}{Results and Discussion\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Massachusetts dataset}{6}{subsection.5.1}}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:chen2016deeplab}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Correctness at breakeven of HF-FCN v.s. \cite  {IEEEexample:mnih2013machine}\cite  {IEEEexample:saito2016multiple}\cite  {IEEEexample:alshehhi2017simultaneous}\cite  {IEEEexample:Long_2015_CVPR}\cite  {IEEEexample:badrinarayanan2017segnet} \cite  {IEEEexample:ronneberger2015u}\cite  {IEEEexample:chen2016deeplab}on Massachusetts test set. Cost time is computed in the same computer with a single NVIDIA Titan 12GB GPU}}{7}{table.3}}
\newlabel{table:Mass-results}{{III}{7}{Correctness at breakeven of HF-FCN v.s. \cite {IEEEexample:mnih2013machine}\cite {IEEEexample:saito2016multiple}\cite {IEEEexample:alshehhi2017simultaneous}\cite {IEEEexample:Long_2015_CVPR}\cite {IEEEexample:badrinarayanan2017segnet} \cite {IEEEexample:ronneberger2015u}\cite {IEEEexample:chen2016deeplab}on Massachusetts test set. Cost time is computed in the same computer with a single NVIDIA Titan 12GB GPU\relax }{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Input aerial image. (b-g) Feature maps of U1\_1, U1\_2, U2\_2, U3\_3, U4\_3, U5\_3, respectively. (h) Predicted label map. All the images are normalized to the range of ${0-255}$.}}{7}{figure.6}}
\newlabel{fig:feature_maps}{{6}{7}{(a) Input aerial image. (b-g) Feature maps of U1\_1, U1\_2, U2\_2, U3\_3, U4\_3, U5\_3, respectively. (h) Predicted label map. All the images are normalized to the range of ${0-255}$}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The relaxed precision-recall curves from HF-FCN variants with two slack paramters. The biggest gap occurs between HF-FCN16s and HF-FCN8s, which indicates the most additional information coming from middle layers.}}{7}{figure.7}}
\newlabel{fig:Mass-variants-PR}{{7}{7}{The relaxed precision-recall curves from HF-FCN variants with two slack paramters. The biggest gap occurs between HF-FCN16s and HF-FCN8s, which indicates the most additional information coming from middle layers}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Vaihingen dataset}{7}{subsection.5.2}}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:marmanis2016semantic}
\citation{IEEEexample:unknown}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:marmanis2016semantic}
\citation{IEEEexample:unknown}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces (a) input images. (b) Results of Mnih-CNN+CRF. (c) Results of Satio\discretionary {-}{}{}multi\discretionary {-}{}{}MA\&CIS. (d) Results of FCN4s . (e) Results of SegNet. (f) Results of DeepLab\_V2. (g) Results of U-Net. (h) Our results. TP are shown in green, FP are shown in blue and FN are in red.}}{8}{figure.9}}
\newlabel{fig:Mass-visi-result}{{9}{8}{(a) input images. (b) Results of Mnih-CNN+CRF. (c) Results of Satio\-multi\-MA\&CIS. (d) Results of FCN4s . (e) Results of SegNet. (f) Results of DeepLab\_V2. (g) Results of U-Net. (h) Our results. TP are shown in green, FP are shown in blue and FN are in red}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Prediction results of HF-FCN, HF-FCN4s, HF-FCN8s and HF-FCN16s. The yellow box shows the continuous refinement of the tiny buildings. The red and blue boxes show the mutual promotion and contradiction between different layers.}}{8}{figure.8}}
\newlabel{fig:Mass-variants-visi}{{8}{8}{Prediction results of HF-FCN, HF-FCN4s, HF-FCN8s and HF-FCN16s. The yellow box shows the continuous refinement of the tiny buildings. The red and blue boxes show the mutual promotion and contradiction between different layers}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces (a) is weights learned by F1\_1, (b) is weights learned by F4\_1, (c) is weights learned by Part 3.}}{8}{figure.10}}
\newlabel{fig:Mass-weights}{{10}{8}{(a) is weights learned by F1\_1, (b) is weights learned by F4\_1, (c) is weights learned by Part 3}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Performance comparison of the results of different inputs and methods on Vaihigen data set. \leavevmode {\color  {red}(xuejin:What are the numbers in the Img column?)}}}{8}{table.4}}
\newlabel{table:vaihigen-3-4-5in-comp}{{IV}{8}{Performance comparison of the results of different inputs and methods on Vaihigen data set. \cxj {What are the numbers in the Img column?}\relax }{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Potsdam dataset}{8}{subsection.5.3}}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:zhou20112}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Results of HF-FCN variants on Vaihingen dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Vaihingen dataset respectively.\leavevmode {\color  {red}(xuejin:Bigger font)}}}{9}{figure.11}}
\newlabel{fig:Vaihingen-variants}{{11}{9}{Results of HF-FCN variants on Vaihingen dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Vaihingen dataset respectively.\cxj {Bigger font}\relax }{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Results of HF-FCN variants on Potsdam dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Potsdam dataset respectively.}}{9}{figure.12}}
\newlabel{fig:Potsdam-variants}{{12}{9}{Results of HF-FCN variants on Potsdam dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Potsdam dataset respectively}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Prediction results on Vaihingen dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red.}}{9}{figure.13}}
\newlabel{fig:Vaihingen-3-4-5in}{{13}{9}{Prediction results on Vaihingen dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Results of different methods. (a) is input image, (b)(d)(g) are results of \cite  {IEEEexample:audebert2017deep}, (c) is result of \cite  {IEEEexample:marmanis2016semantic}, (f) is result of \cite  {IEEEexample:unknown}, (g) is our result. The blue and yellow frames show some details between these methods.}}{9}{figure.14}}
\newlabel{fig:Vaihingen-compared-others}{{14}{9}{Results of different methods. (a) is input image, (b)(d)(g) are results of \cite {IEEEexample:audebert2017deep}, (c) is result of \cite {IEEEexample:marmanis2016semantic}, (f) is result of \cite {IEEEexample:unknown}, (g) is our result. The blue and yellow frames show some details between these methods}{figure.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Performance comparison of the results of different inputs and methods on Potsdam data set}}{9}{table.5}}
\newlabel{table:Potsdam-3-4-5in-comp}{{V}{9}{Performance comparison of the results of different inputs and methods on Potsdam data set\relax }{table.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Application}{9}{section.6}}
\newlabel{sec:app}{{VI}{9}{Application\relax }{section.6}{}}
\bibstyle{IEEEtran}
\bibdata{IEEEexample}
\bibcite{IEEEexample:huertas1988detecting}{1}
\bibcite{IEEEexample:noronha2001detection}{2}
\bibcite{IEEEexample:nosrati2009novel}{3}
\bibcite{IEEEexample:izadi2012three}{4}
\bibcite{IEEEexample:wang2015efficient}{5}
\bibcite{IEEEexample:cote2013automatic}{6}
\bibcite{IEEEexample:peng2005improved}{7}
\bibcite{IEEEexample:sirmacek2009urban}{8}
\bibcite{IEEEexample:mnih2013machine}{9}
\bibcite{IEEEexample:saito2016multiple}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Prediction results on potsdam dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red.}}{10}{figure.15}}
\newlabel{fig:Potsdam-3-4-5in-visi}{{15}{10}{Prediction results on potsdam dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Results of different methods. The second column is the results of using only the FCN with CIR. Pairwise CRF fusion shows the result of fusing FCN-8s\_CIR with LiDAR data in a pairwise CRF. Higher-order CRF are used to generate the results shown in third column. Our results are shown in last colunm.}}{10}{figure.16}}
\newlabel{fig:Potsdam-compared-others}{{16}{10}{Results of different methods. The second column is the results of using only the FCN with CIR. Pairwise CRF fusion shows the result of fusing FCN-8s\_CIR with LiDAR data in a pairwise CRF. Higher-order CRF are used to generate the results shown in third column. Our results are shown in last colunm}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The 3D modelling of Veihingen dataset. The single building model and its corresponding optical patch were shown together.}}{10}{figure.17}}
\newlabel{fig:Vaihingen-3Dmodeling}{{17}{10}{The 3D modelling of Veihingen dataset. The single building model and its corresponding optical patch were shown together}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The 3D modelling of Potsdam dataset. The single building model and its corresponding optical patch were shown together.}}{10}{figure.18}}
\newlabel{fig:Potsdam-3Dmodeling}{{18}{10}{The 3D modelling of Potsdam dataset. The single building model and its corresponding optical patch were shown together}{figure.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{10}{section.7}}
\newlabel{Sec:Con}{{VII}{10}{Conclusion\relax }{section.7}{}}
\@writefile{toc}{\contentsline {section}{References}{10}{section*.1}}
\bibcite{IEEEexample:alshehhi2017simultaneous}{11}
\bibcite{IEEEexample:zhao2017contextually}{12}
\bibcite{IEEEexample:paisitkriangkrai2015effective}{13}
\bibcite{IEEEexample:liu2017dense}{14}
\bibcite{IEEEexample:audebert2017deep}{15}
\bibcite{IEEEexample:kampffmeyer2017urban}{16}
\bibcite{IEEEexample:he2017multi}{17}
\bibcite{IEEEexample:Long_2015_CVPR}{18}
\bibcite{IEEEexample:badrinarayanan2017segnet}{19}
\bibcite{IEEEexample:hoffman2016learning}{20}
\bibcite{IEEEexample:chen2016deeplab}{21}
\bibcite{IEEEexample:vemulapalli2016gaussian}{22}
\bibcite{IEEEexample:he2016deep}{23}
\bibcite{IEEEexample:szegedy2015going}{24}
\bibcite{IEEEexample:szegedy2016rethinking}{25}
\bibcite{IEEEexample:szegedy2017inception}{26}
\bibcite{IEEEexample:xie2017aggregated}{27}
\bibcite{IEEEexample:zuo2016hf}{28}
\bibcite{IEEEexample:ronneberger2015u}{29}
\bibcite{IEEEexample:lin2017feature}{30}
\bibcite{IEEEexample:marmanis2016semantic}{31}
\bibcite{IEEEexample:unknown}{32}
\bibcite{IEEEexample:zhou20112}{33}
