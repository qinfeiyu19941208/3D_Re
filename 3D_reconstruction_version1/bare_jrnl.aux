\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:noronha2001detection}
\citation{IEEEexample:nosrati2009novel}
\citation{IEEEexample:izadi2012three}
\citation{IEEEexample:wang2015efficient}
\citation{IEEEexample:cote2013automatic}
\citation{IEEEexample:peng2005improved}
\citation{IEEEexample:sirmacek2009urban}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:zhao2017contextually}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:liu2017dense}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:kampffmeyer2017urban}
\citation{IEEEexample:he2017multi}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{I}{1}{Introduction\relax }{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of remote sensing patches with different kinds of challenges. (a) Shadow occlusion in green frame. (b) Low inter-class differences. (c) High intra class variance. (d) A lot of tiny buildings close to each other.}}{1}{figure.1}}
\newlabel{fig:intro}{{1}{1}{Examples of remote sensing patches with different kinds of challenges. (a) Shadow occlusion in green frame. (b) Low inter-class differences. (c) High intra class variance. (d) A lot of tiny buildings close to each other}{figure.1}{}}
\citation{IEEEexample:huertas1988detecting}
\citation{IEEEexample:noronha2001detection}
\citation{IEEEexample:nosrati2009novel}
\citation{IEEEexample:izadi2012three}
\citation{IEEEexample:wang2015efficient}
\citation{IEEEexample:cote2013automatic}
\citation{IEEEexample:peng2005improved}
\citation{IEEEexample:sirmacek2009urban}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:zhao2017contextually}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:he2017multi}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:liu2017dense}
\citation{IEEEexample:paisitkriangkrai2015effective}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:kampffmeyer2017urban}
\citation{IEEEexample:hoffman2016learning}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}}
\newlabel{Sec:RelatedWork}{{II}{2}{Related Work\relax }{section.2}{}}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:vemulapalli2016gaussian}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:he2016deep}
\citation{IEEEexample:szegedy2015going}
\citation{IEEEexample:szegedy2016rethinking}
\citation{IEEEexample:szegedy2017inception}
\citation{IEEEexample:xie2017aggregated}
\citation{IEEEexample:zhao2017contextually}
\citation{IEEEexample:he2016deep}
\citation{IEEEexample:zuo2016hf}
\citation{IEEEexample:zuo2016hf}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The first line shows the overview of our network. The second row shows the details of fusion operation. The one on the left is a case where the input is equal to the output and the one on the right is the case of the input not equal to the output.}}{3}{figure.2}}
\newlabel{fig:Fusion-Operation}{{2}{3}{The first line shows the overview of our network. The second row shows the details of fusion operation. The one on the left is a case where the input is equal to the output and the one on the right is the case of the input not equal to the output}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Hierarchically Fused Fully Convolutional Network}{3}{section.3}}
\newlabel{Sec:HF-FCN}{{III}{3}{Hierarchically Fused Fully Convolutional Network\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Network Architecture}{3}{subsection.3.1}}
\citation{table:dataset-composition}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (a) Input aerial image. (b-g) Feature maps of U1\_1, U1\_2, U2\_2, U3\_3, U4\_3, U5\_3, respectively. (h) Predicted label map.}}{4}{figure.4}}
\newlabel{fig:feature_maps}{{4}{4}{(a) Input aerial image. (b-g) Feature maps of U1\_1, U1\_2, U2\_2, U3\_3, U4\_3, U5\_3, respectively. (h) Predicted label map}{figure.4}{}}
\newlabel{fature_selection}{{1}{4}{Network Architecture\relax }{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Network Training}{4}{subsection.3.2}}
\newlabel{loss}{{2}{4}{Network Training\relax }{equation.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{4}{section.4}}
\newlabel{Sec:exp}{{IV}{4}{Experiments\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Dataset Description}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0a}Massachusetts dataset}{4}{paragraph.4.1.0.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Overall architecture of HF-FCN. The input of HF-FCN could be 3, 4 or 5 channels for RGB, DSM, nDSM. The backbone network is VGG16 network which contribute to the Level 1. The F1\_1 in Level 1 indicates the feature maps generated by conv1\_1. In Level 2, 13 upsampled feature maps are cropped to the same size of input. $\times $2 next to the fusion operation means 2 times of upper sampling. U1\_1 in Level 2 means the upsampled feature map of F1\_1, and so forth. \leavevmode {\color  {red}(xuejin:What is the different between our network with U-Net or other FCN networks?)} }}{5}{figure.3}}
\newlabel{fig:network_architecture}{{3}{5}{Overall architecture of HF-FCN. The input of HF-FCN could be 3, 4 or 5 channels for RGB, DSM, nDSM. The backbone network is VGG16 network which contribute to the Level 1. The F1\_1 in Level 1 indicates the feature maps generated by conv1\_1. In Level 2, 13 upsampled feature maps are cropped to the same size of input. $\times $2 next to the fusion operation means 2 times of upper sampling. U1\_1 in Level 2 means the upsampled feature map of F1\_1, and so forth. \cxj {What is the different between our network with U-Net or other FCN networks?}\relax }{figure.3}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0b}Vaihingen dataset}{5}{paragraph.4.1.0.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-A}0c}Potsdam dataset}{5}{paragraph.4.1.0.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sample patches on the three datasets (a) Massachusetts dataset (b) Vaihingen dataset (c) Potsdam dataset}}{5}{figure.5}}
\newlabel{fig:dataset_sample}{{5}{5}{Sample patches on the three datasets (a) Massachusetts dataset (b) Vaihingen dataset (c) Potsdam dataset\relax }{figure.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Composition of dataset}}{5}{table.1}}
\newlabel{table:dataset-composition}{{I}{5}{Composition of dataset\relax }{table.1}{}}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:chen2016deeplab}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:mnih2013machine}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:saito2016multiple}
\citation{IEEEexample:alshehhi2017simultaneous}
\citation{IEEEexample:Long_2015_CVPR}
\citation{IEEEexample:badrinarayanan2017segnet}
\citation{IEEEexample:ronneberger2015u}
\citation{IEEEexample:chen2016deeplab}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Parameters for Network Training}}{6}{table.2}}
\newlabel{table:Train-Parameter}{{II}{6}{Parameters for Network Training\relax }{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Training Settings}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Evaluation Metrics}{6}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Discussion}{6}{section.5}}
\newlabel{Sec:Res}{{V}{6}{Results and Discussion\relax }{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces HF-FCN variants. The feature maps generated from final group are fused into a coarse result, which is HF-FCN16s. The variant called HF-FCN8s concatenates the feature maps from the last 2 groups with the same fusion operation, and so on.}}{6}{figure.6}}
\newlabel{fig:Variants}{{6}{6}{HF-FCN variants. The feature maps generated from final group are fused into a coarse result, which is HF-FCN16s. The variant called HF-FCN8s concatenates the feature maps from the last 2 groups with the same fusion operation, and so on}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Massachusetts dataset}{6}{subsection.5.1}}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:marmanis2016semantic}
\citation{IEEEexample:unknown}
\citation{IEEEexample:audebert2017deep}
\citation{IEEEexample:marmanis2016semantic}
\citation{IEEEexample:unknown}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Correctness at breakeven of HF-FCN v.s. \cite  {IEEEexample:mnih2013machine}\cite  {IEEEexample:saito2016multiple}\cite  {IEEEexample:alshehhi2017simultaneous} on Massachusetts test set. Cost time is computed in the same computer with a single NVIDIA Titan 12GB GPU}}{7}{table.3}}
\newlabel{table:Mass-results}{{III}{7}{Correctness at breakeven of HF-FCN v.s. \cite {IEEEexample:mnih2013machine}\cite {IEEEexample:saito2016multiple}\cite {IEEEexample:alshehhi2017simultaneous} on Massachusetts test set. Cost time is computed in the same computer with a single NVIDIA Titan 12GB GPU\relax }{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The relaxed precision-recall curves from HF-FCN variants with two slack paramters. The biggest gap occurs between HF-FCN16s and HF-FCN8s, which indicates the most additional information coming from middle layers.}}{7}{figure.7}}
\newlabel{fig:Mass-variants-PR}{{7}{7}{The relaxed precision-recall curves from HF-FCN variants with two slack paramters. The biggest gap occurs between HF-FCN16s and HF-FCN8s, which indicates the most additional information coming from middle layers}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Prediction results of HF-FCN, HF-FCN4s, HF-FCN8s and HF-FCN16s. The yellow box shows the continuous refinement of the tiny buildings. The red and blue boxes show the mutual promotion and contradiction between different layers.}}{7}{figure.8}}
\newlabel{fig:Mass-variants-visi}{{8}{7}{Prediction results of HF-FCN, HF-FCN4s, HF-FCN8s and HF-FCN16s. The yellow box shows the continuous refinement of the tiny buildings. The red and blue boxes show the mutual promotion and contradiction between different layers}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces (a) is weights learned by F1\_1, (b) is weights learned by F2\_1, (c) is weights learned by F3\_1, (d) is weights learned by F4\_1, (e) is weights learned by F5\_1, (f) is weights learned by Level 2.}}{7}{figure.10}}
\newlabel{fig:Mass-weights}{{10}{7}{(a) is weights learned by F1\_1, (b) is weights learned by F2\_1, (c) is weights learned by F3\_1, (d) is weights learned by F4\_1, (e) is weights learned by F5\_1, (f) is weights learned by Level 2}{figure.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Vaihingen dataset}{7}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces (a) input images. (b) Results of Mnih-CNN+CRF. (c) Results of Satio\discretionary {-}{}{}multi\discretionary {-}{}{}MA\&CIS. (d) Results of FCN4s . (e) Results of SegNet. (f) Results of DeepLab\_V2. (g) Results of U-Net. (h) Our results. TP are shown in green, FP are shown in blue and FN are in red.}}{8}{figure.9}}
\newlabel{fig:Mass-visi-result}{{9}{8}{(a) input images. (b) Results of Mnih-CNN+CRF. (c) Results of Satio\-multi\-MA\&CIS. (d) Results of FCN4s . (e) Results of SegNet. (f) Results of DeepLab\_V2. (g) Results of U-Net. (h) Our results. TP are shown in green, FP are shown in blue and FN are in red}{figure.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Performance comparison of the results of different inputs on Vaihigen data set. \leavevmode {\color  {red}(xuejin:What are the numbers in the Img column?)}}}{8}{table.4}}
\newlabel{table:vaihigen-3-4-5in-comp}{{IV}{8}{Performance comparison of the results of different inputs on Vaihigen data set. \cxj {What are the numbers in the Img column?}\relax }{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Results of HF-FCN variants on Vaihingen dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Vaihingen dataset respectively.\leavevmode {\color  {red}(xuejin:Bigger font)}}}{8}{figure.11}}
\newlabel{fig:Vaihingen-variants}{{11}{8}{Results of HF-FCN variants on Vaihingen dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Vaihingen dataset respectively.\cxj {Bigger font}\relax }{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Results of HF-FCN variants on Potsdam dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Potsdam dataset respectively.}}{8}{figure.12}}
\newlabel{fig:Potsdam-variants}{{12}{8}{Results of HF-FCN variants on Potsdam dataset. (a) (b) shows the precision, recall and F1\_score of validation set and test set of Potsdam dataset respectively}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Prediction results on Vaihingen dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red.}}{8}{figure.13}}
\newlabel{fig:Vaihingen-3-4-5in}{{13}{8}{Prediction results on Vaihingen dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red}{figure.13}{}}
\citation{IEEEexample:zhou20112}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Results of different methods. (a) is input image, (b)(d)(g) are results of \cite  {IEEEexample:audebert2017deep}, (c) is result of \cite  {IEEEexample:marmanis2016semantic}, (f) is result of \cite  {IEEEexample:unknown}, (g) is our result. The blue and yellow frames show some details between these methods.}}{9}{figure.14}}
\newlabel{fig:Vaihingen-compared-others}{{14}{9}{Results of different methods. (a) is input image, (b)(d)(g) are results of \cite {IEEEexample:audebert2017deep}, (c) is result of \cite {IEEEexample:marmanis2016semantic}, (f) is result of \cite {IEEEexample:unknown}, (g) is our result. The blue and yellow frames show some details between these methods}{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Potsdam dataset}{9}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Application}{9}{section.6}}
\newlabel{sec:app}{{VI}{9}{Application\relax }{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Prediction results on potsdam dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red.}}{9}{figure.15}}
\newlabel{fig:Potsdam-3-4-5in-visi}{{15}{9}{Prediction results on potsdam dataset. (a) (b) (c) shows results of the 3-channel input, 4-channel input and 5-channel input of Vaihingen dataset respectively. Here, TP are shown in green, FP are shown in blue and FN are in red}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Results of different methods. The second column is the results of using only the FCN with CIR. Pairwise CRF fusion shows the result of fusing FCN-8s\_CIR with LiDAR data in a pairwise CRF. Higher-order CRF are used to generate the results shown in third column. Our results are shown in last colunm.}}{9}{figure.16}}
\newlabel{fig:Potsdam-compared-others}{{16}{9}{Results of different methods. The second column is the results of using only the FCN with CIR. Pairwise CRF fusion shows the result of fusing FCN-8s\_CIR with LiDAR data in a pairwise CRF. Higher-order CRF are used to generate the results shown in third column. Our results are shown in last colunm}{figure.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{9}{section.7}}
\newlabel{Sec:Con}{{VII}{9}{Conclusion\relax }{section.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The 3D modelling of Veihingen dataset. The single building model and its corresponding optical patch were shown together.}}{9}{figure.17}}
\newlabel{fig:Vaihingen-3Dmodeling}{{17}{9}{The 3D modelling of Veihingen dataset. The single building model and its corresponding optical patch were shown together}{figure.17}{}}
\bibstyle{IEEEtran}
\bibdata{IEEEexample}
\bibcite{IEEEexample:huertas1988detecting}{1}
\bibcite{IEEEexample:noronha2001detection}{2}
\bibcite{IEEEexample:nosrati2009novel}{3}
\bibcite{IEEEexample:izadi2012three}{4}
\bibcite{IEEEexample:wang2015efficient}{5}
\bibcite{IEEEexample:cote2013automatic}{6}
\bibcite{IEEEexample:peng2005improved}{7}
\bibcite{IEEEexample:sirmacek2009urban}{8}
\bibcite{IEEEexample:mnih2013machine}{9}
\bibcite{IEEEexample:saito2016multiple}{10}
\bibcite{IEEEexample:alshehhi2017simultaneous}{11}
\bibcite{IEEEexample:zhao2017contextually}{12}
\bibcite{IEEEexample:paisitkriangkrai2015effective}{13}
\bibcite{IEEEexample:liu2017dense}{14}
\bibcite{IEEEexample:audebert2017deep}{15}
\bibcite{IEEEexample:kampffmeyer2017urban}{16}
\bibcite{IEEEexample:he2017multi}{17}
\bibcite{IEEEexample:Long_2015_CVPR}{18}
\bibcite{IEEEexample:badrinarayanan2017segnet}{19}
\bibcite{IEEEexample:hoffman2016learning}{20}
\bibcite{IEEEexample:chen2016deeplab}{21}
\bibcite{IEEEexample:vemulapalli2016gaussian}{22}
\bibcite{IEEEexample:he2016deep}{23}
\bibcite{IEEEexample:szegedy2015going}{24}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Performance comparison of the results of different inputs on Potsdam data set}}{10}{table.5}}
\newlabel{table:Potsdam-3-4-5in-comp}{{V}{10}{Performance comparison of the results of different inputs on Potsdam data set\relax }{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The 3D modelling of Potsdam dataset. The single building model and its corresponding optical patch were shown together.}}{10}{figure.18}}
\newlabel{fig:Potsdam-3Dmodeling}{{18}{10}{The 3D modelling of Potsdam dataset. The single building model and its corresponding optical patch were shown together}{figure.18}{}}
\@writefile{toc}{\contentsline {section}{References}{10}{section*.1}}
\bibcite{IEEEexample:szegedy2016rethinking}{25}
\bibcite{IEEEexample:szegedy2017inception}{26}
\bibcite{IEEEexample:xie2017aggregated}{27}
\bibcite{IEEEexample:zuo2016hf}{28}
\bibcite{IEEEexample:ronneberger2015u}{29}
\bibcite{IEEEexample:marmanis2016semantic}{30}
\bibcite{IEEEexample:unknown}{31}
\bibcite{IEEEexample:zhou20112}{32}
