\section{Related Work}
\label{Sec:RelatedWork}


Building extraction is one of the most fundamental problems in remote sensing domain, which has been studied for nearly 30 years.
As time goes by, many research achievements have sprung up.
We roughly divide these methods into three groups: one is based on the shape prior, another is based on the energy function and machine learning third. Meanwhile, the methods of machine learning could be divide into two parts: one is shallow networks and the other is deep learning methods.
Here we briefly review some representative methods that have evolved in the past decades in the different groups respectively.
Moreover, some related work which are popular in compute vision domain similar to our task are also introduced.
\cxj{More related work on city modeling/urban modeling. Maybe facade modeling.}



\textbf{Shape Prior based Methods} During early days, methods are mainly based on the hypothesis of prior knowledge.
Huertas and Nevatia \cite{IEEEexample:huertas1988detecting} assumed that buildings are rectangular or composed of rectangular components.
Based on it, the approach detected lines and corners, traced object boundaries and used shadows to verify.
Later, a system \cite{IEEEexample:noronha2001detection} for building detection and modelling was proposed with the assumption that the roofs were flat or symmetrical and walls were vertical.
With known ground height and detected rooftop, the reconstructed models could be soon obtained.
Further, Noronha and Nosrati \cite{IEEEexample:nosrati2009novel} transformed the line and intersection points in remote sensing images into a graph presentation, and turned the problem of polygon finding into the one that finding loops in the graph.
It was still estimated on assumption that the buildings are polygonal.
Later, Izadi and Saeedi\cite{IEEEexample:izadi2012three} presented a complete system for building detection and modelling.
In the stage of extracting buildings, a tree consisting of intersection points of lines was created and refined according to the found hypotheses.
The sun azimuth and elevation angles were used to estimate the height with existing shadows afterwards.
In recent years, very high resolution (VHR) optical satellite imagery could be obtained easily.
Based on it, Wang et al~\cite{IEEEexample:wang2015efficient} proposed an efficient method for automatic rectangular building extraction by detecting line segments and grouping them based on path integrity and closed contour. The method depends on the clear remote sensing images and accurate line segmentation heavily.
\cxj{If there are two authors, say A and B proposed.... if more than two authors, say A et al. ..}


The aforementioned shape-based methods have a good performance in rural scenes with low density of buildings.
Neverthless, there are several limitations of these methods.
First, the shape-based methods inherently limited to handle buildings of arbitrary shapes.
Second, they may failed to deal with complicated cases, for instance, buildings are close to each other, which thereby is hard to adapt to today's applications.
Third, the algorithms using shadows to verify corners and estimate height are greatly limited by obvious shadows and sparse building environment.


\textbf{Energy Function based Methods} Later, several energy-based methods in image segmentation domain have been applied to automatic rooftop extraction.
Cote and Saeedi\cite{IEEEexample:cote2013automatic} proposed a level set evolution method that employed detected corners as endpoints of the initial curves.
Peng et al~\cite{IEEEexample:peng2005improved} used an improved snake model to refine the coarse segmentation results.
Later, the urban-region-detection problems were casted as one of multiple subgraph matching by Sirmacek and Unsalan\cite{IEEEexample:sirmacek2009urban}.
They considered each SIFT keypoint as a vertex, neighborhood between vertexes as edges of the graph and converted the original image segmentation problem into a graph-cut optimization process.

Experiment results displayed in the above works reveal that energy-based methods limit by a good initialization.
And it is generally known that energy-based methods are greatly influenced by the nature of the images.
That is to say, the above mentioned methods are not applicable to the situation where high altitude remote sensing images of intensive buildings with severe shadow occlusion.


\textbf{Shallow Networks} Over the past decade, machine learning have achieved great success in the field of computer vision.
There are significant amount of efforts on building extraction task.
Mnih \cite{IEEEexample:mnih2013machine} proposed a shallow patch-based network which has five layers with a 64 by 64 aerial patch as input.
The output of the network was processed by conditional random fields (CRFs) to constrain the segmentation continuity.
Afterwards, Satio et al. \cite{IEEEexample:saito2016multiple} putted forward two major strategies to improve the performance of \cite{IEEEexample:mnih2013machine}.
The one was a channel-wise inhibited softmax (CIS) for getting a multi-label prediction result, the other was model averaging (MA) with spatial displacement for enhancing the prediction result.
Later, Alshehhi et al. \cite{IEEEexample:alshehhi2017simultaneous} adjusted the architecture of \cite{IEEEexample:mnih2013machine} through changing the kernel size of convolutional layers and replacing the last fully connection layer with the average pooling layer.
Alternative post-processing strategies such as CRFs and multi-scales were also used to improve the final prediction results.
At the same time, some other methods took advantage of the feature extraction capability of CNNs to generate feature descriptions of patches for further segmentation; for instance,
Paisitkriangkrai et al. \cite{IEEEexample:paisitkriangkrai2015effective} made use of both the CNN and hand-craft extracted features and combined them together to generate predicted labels of each patch.
The CRFs was also used as post-processing to get a sound result.
Unlike \cite{IEEEexample:paisitkriangkrai2015effective}, \cite{IEEEexample:he2017multi} put forward a multi-label pixelwise classification method using the feature vector extracted by a CNN to train a Support Vector Machine (SVM) for classification.
Other appearance information, such as edges \cite{IEEEexample:zhao2017contextually} are also harnessed to guide the shallow network to extract buildings.


Although the above mentioned methods have exceeded the traditional methods, there are still several disadvantages. 
(a) The methods using shallow networks always cast the problem of building segmentation as a patch classification problem. It has a great impact on the segmentation accuracy.
(b) Most of them are processed by at least one kind of post-processing, which is time-consuming.

\textbf{Deep Learning} More recently, Long et al. \cite{IEEEexample:Long_2015_CVPR} illustrated that Fully Convolutional Networks (FCN) handle the problem of multi-label pixel-wise classification better.
Hence, Liu et al. \cite{IEEEexample:liu2017dense} did a further research on the formulation proposed by Paisitkriangkrai \cite{IEEEexample:paisitkriangkrai2015effective} but with FCN instead of shallow network and applied a higher-order CRFs as post-processing.
Unlike traditional CRFs, the label consistency for the pixels within the same segment were enforced by higher-order CRFs.
In order to reduce the information loss during pooling stage and accelerate the decoding of FCN, SegNet \cite{IEEEexample:badrinarayanan2017segnet} delivered pooling indices computed in the max-pooling to the decoder.
It eliminated the need of learning during the up-sample stage and retained partial information during pooling stage while preserving segmentation performance well.
Accordingly, Audebert et al. \cite{IEEEexample:audebert2017deep} used SegNet architecture for semantic labeling of remote sensing images and got better prediction results compared to the traditional methods.
Later, Kampffmeyer at al. \cite{IEEEexample:kampffmeyer2017urban} proposed a novel idea that using CNN with missing data for urban land cover classification.
The idea is came from a modality hallucination architecture proposed by Hoffman et al. \cite{IEEEexample:hoffman2016learning} which solved the problem that missing some kinds of data during test process.


Above-mentioned deep learning models have exceeded the traditional methods significantly, but most of them completely ignored important hierarchical features encoded in the CNNs.
But for building extraction task, the lost low-level and middle-level information are critical to the final segmentation result.


\textbf{Computer Vision} In the filed of computer vision, the FCNs \cite{IEEEexample:Long_2015_CVPR} were introduced as a powerful method for semantic segmentation and already achieved great success.
 But, along with the deepening of network, the feature maps with lower resolution which causes the segmentation accuracy decline.
 In order to weaken the influence caused by deepen of network, Chen et al.\cite{IEEEexample:chen2016deeplab} proposed a atrous convolution which enlarged the receptive field and reduced the number of pooling layers at the same time.
 Vemulapalli et al.\cite{IEEEexample:vemulapalli2016gaussian} further extended the Deeplab \cite{IEEEexample:chen2016deeplab} with a pairwise network and proposed a Gaussian Conditional Random Field Network for more continuous segmentation results.
 Afterwards, with the advent of the powerful networks such as ResNet\cite{IEEEexample:he2016deep}, GoogLeNet\cite{IEEEexample:szegedy2015going} and their variants \cite{IEEEexample:szegedy2016rethinking}\cite{IEEEexample:szegedy2017inception}\cite{IEEEexample:xie2017aggregated}, a large amount of literature made use of these networks as their main structure for semantic segmentation.
 Zhao et al.\cite{IEEEexample:zhao2017contextually} recently developed a pyramid pooling module following the ResNet\cite{IEEEexample:he2016deep} to get multi-scale feature maps and connected them with the feature maps which before pyramid pooling to create the final prediction.
 Zuo et al.\cite{IEEEexample:zuo2016hf} described a hierarchically fused fully convolutional network, which combined the feature maps from each group of VGG16 Net to generate the final prediction.
 In this paper, we extend the work of\cite{IEEEexample:zuo2016hf} and proposed a simple but effective fusion operation that could be easily combined to the general network.
 We also explore the effect of different layers of features on the final result. The details of our idea will be described in the next section.


The most relevant work of our work are U-Net\cite{IEEEexample:ronneberger2015u} and FPN \cite{IEEEexample:lin2017feature}. Differ from the U-Net which simple concatenates the feature maps from encoder to decoder, we apply a fusion operation firstly to fuse the feature maps created in the same convolution layers in the path of encoder to get more richer features. The main idea of FPN is leveraging the encoder part as a feature pyramid, with predictions made independently at all levels. During the top-down path of FPN, it only exploit the feature maps come from the each stage's last residual block, but we take advantage of the all feature maps from the each stage. Moreover, we upsample the feature maps from each stage to the same resolution of the input and apply a hierarchical fusion operation to fuse the upsampled feature maps to a final prediction instead of directly predicting from each stage. That is to say, we only make a prediction rather than multiple predictions.






\cxj{Need a paragraph to discuss recent semantic segmentation networks. }

\cxj{Also cite our accv paper and describe the relationship/difference of this journal paper with it.}

