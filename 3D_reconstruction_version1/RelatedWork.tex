\section{Related Work}
\label{Sec:RelatedWork}


Building extraction is one of the most fundamental problems in remote sensing domain, which has been studied for nearly 30 years. Meanwhile, many research achievements have sprung up. As time goes by, we can roughly divide these methods into three groups: one is based on the shape prior, another is based on the energy function and machine learning third. Here we briefly review some representative methods that have evolved in the past decades.
\cxj{More related work on city modeling/urban modeling. Maybe facade modeling.}



During early days, methods are mainly based on the hypothesis of prior knowledge. Huertas et al \cite{IEEEexample:huertas1988detecting} assumed that buildings are rectangular or composed of rectangular components. Based on this, the approach detected lines and corners, traced object boundaries and used shadows to verify. Later, a system \cite{IEEEexample:noronha2001detection} for building detection and modelling was proposed with the assumption that the roofs were flat or symmetrical and walls were vertical. Using known ground height and detected rooftop, the reconstructed models could be soon obtained. Further, Nosrati \cite{IEEEexample:nosrati2009novel} transformed the line and intersection points of the image into a graph presentation, and turned the problem of polygon finding into the one that finding loops in the graph. However, it was still estimated on assumption that the buildings are polygonal. In addition, Izadi \cite{IEEEexample:izadi2012three} presented a complete system for building detection and modelling. In the stage of building detection, a tree consisting of intersection points of lines was created and refined based on the found hypotheses. The sun azimuth and elevation angles were used to estimate the height with existing shadows afterwards. As the height of buildings estimated, the three-dimensional polygonal building models were built. In recent years, very high resolution (VHR) optical satellite imagery could be obtained easily. Hence, Wang et al~\cite{IEEEexample:wang2015efficient} proposed an efficient method for automatic rectangular building extraction from VHR remote sensing images by detecting line segments and grouping lines based on path integrity and closed contour search.
\cxj{If there are two authors, say A and B proposed.... if more than two authors, say A et al. ..}


The aforementioned shape-based methods have a good performance in rural scenes with low density of buildings. Neverthless, there are some limitations of these methods. 
First, the shape-based methods inherently limited to handle buildings of arbitrary shapes. 
Second, these methods may failed to deal with complicated cases, for instance, buildings are close to each other, which thereby is hard to adapt to today's applications. Third, the method using shadows to verify corners and estimate height is greatly limited to obvious shadows and sparse building environment. 


Later, several energy-based methods have been applied in automatic rooftop extraction. Cote \cite{IEEEexample:cote2013automatic} employed corner detection as an initial estimate of the roof, and then refined with level set evolution. Peng and Liu \cite{IEEEexample:peng2005improved} proposed an approach that segments remote sensing images into high objects, ground and shadow regions, with further refined by an improved snake model. The urban-region-detection problems were casted as one of multiple subgraph matching by Sirmacek et al \cite{IEEEexample:sirmacek2009urban}. They considered each SIFT keypoint as a vertex, neighborhood between vertexs as edge of the graph and formulated the problem of building detection in terms of graph cut.


Over the past decade, CNNs have achieved great success in the field of computer vision. There are significant amount of efforts on semantic pixel-level classification for extraction buildings in remote sensing. A shallow patch-based network was proposed by Mnih \cite{IEEEexample:mnih2013machine} which has only five layers with a 64 by 64 aerial patch as input. And the output of the network was processed by conditional random fields (CRFs). Afterwards, Satio et al.\cite{IEEEexample:saito2016multiple} applied two major strategies to improve the performance of the network. One was a channel-wise inhibited softmax (CIS) for getting a multi-label prediction result, the other was model averaging with spatial displacement (MA) for enhancing the prediction result. Alshehhi et al. \cite{IEEEexample:alshehhi2017simultaneous} also adjusted the architecture of network proposed by Mnih through changing the kernel size of convolutional layers and replacing the fully connection layer of the last layer with the average pooling layer. Alternative post-processing strategies such as CRFs and multi-scales were used to improve the final prediction results. Some methods took advantage of the feature extraction capability of CNNs to generate feature descriptions of patches. Paisitkriangkrai et al. \cite{IEEEexample:paisitkriangkrai2015effective} made use of both the CNN and hand-craft extracted features, which were combined together to generate predicted labels of each patch. They also used CRFs as post-processing to get a sound result. Zhao et al. \cite{IEEEexample:zhao2017contextually} proposed a method using edge information of VHR to guide semantic segmentation. Unlike \cite{IEEEexample:paisitkriangkrai2015effective}, \cite{IEEEexample:he2017multi} put forward a multi-label pixelwise classification method using the feature vector extracted by a CNN to train a Support Vector Machine (SVM) for classification.\par
\setlength{\parindent}{2ex}More recently, Long \cite{IEEEexample:Long_2015_CVPR} illustrated that Fully Convolutional Networks (FCN) could better handle the problem of multi-label pixel-wise classification. By up-sampling, final predicted result could be the same resolution of the input. Liu et al. \cite{IEEEexample:liu2017dense} did a further research on the formulation proposed by Paisitkriangkrai \cite{IEEEexample:paisitkriangkrai2015effective} but used FCN as the branch of CNN and applied a higher-order CRFs as post-processing. Unlike traditional CRFs, the label consistency for the pixels within the same segment were enforced by higher-order CRFs. In order to reduce the information loss during pooling stage, SegNet \cite{IEEEexample:badrinarayanan2017segnet} delivered pooling indices computed in the max-pooling to the decoder. It eliminated the need of learning during the up-sample stage while achieving good segmentation performance. The SegNet architecture was used by Audebert et al. \cite{IEEEexample:audebert2017deep} for semantic labeling of remote sensing and got better prediction results compared to the traditional methods. Later, Kampffmeyer at al. \cite{IEEEexample:kampffmeyer2017urban} proposed a novel idea that using CNN with missing data for urban land cover classification. The idea came from a modality hallucination architecture proposed by Hoffman et al. \cite{IEEEexample:hoffman2016learning} which learned with side information during training stage. 
\cxj{Need a paragraph to discuss recent semantic segmentation networks. }

\cxj{Also cite our accv paper and describe the relationship/difference of this journal paper with it.}

Although above-mentioned CNN-based models have exceeded the traditional methods significantly, all of them lost important hierarchical features extracted from shallow layers. They usually apply the CNN features from the last layer to get a segmentation result. It may omit tiny objects during the process of pooling, and could not handle the situation when the size of buildings have great difference in distribution. Aiming at this case, a hierarchically fused fully convolutional network is proposed to combine features extracted from each convolutional layer to capture detailed information of input. We will show the details of our idea below.
