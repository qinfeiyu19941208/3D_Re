\section{Related Work}
Building extraction is one of most fundamental problems in remote sensing domain, which has been studied for nearly 30 years. Meanwhile, a lot of research achievements have sprung up. As time goes by, we can roughly divide these methods into three groups: one is based on the shape prior, another is based on the energy function and machine learning third. Here we briefly review some representative methods that have evolved in the past decades.\par
\setlength{\parindent}{2ex}During early days, methods are mainly based on the hypothesis of prior knowledge. Huertas et al \cite{IEEEexample:huertas1988detecting} assumed that buildings are rectangular or composed of rectangular components. Based on it, the approach detected lines and corners, traced object boundaries and used shadows to verify the hypotheses finally. Noronha \cite{IEEEexample:noronha2001detection} later proposed a system for building detection and modelling with the assumption that the roofs were flat or symmetrical and walls were vertical. By known ground height and detected rooftop, the reconstructed models could be soon obtained. Further, Nosrati \cite{IEEEexample:nosrati2009novel} transformed the line and intersection points of the image into a graph presentation, and turned the problem of polygon finding into the one finding loop in the graph. However, it was still built on assumption that the buildings are polygonal. Izadi \cite{IEEEexample:izadi2012three} presented a complete system for building detection and modelling. During building detection, a tree consisting of intersection points of lines was created and refined based on the found hypotheses. The sun azimuth and elevation angles were used to estimate the height with existing shadows. With the height of buildings estimated, the three-dimensional polygonal building model estimation was done. In recent years, very high resolution (VHR) optical satellite imagery could be obtained easily. Wang \cite{IEEEexample:wang2015efficient} proposed an efficient method for automatic rectangular building extraction from VHR remote sensing images by detecting line segments and grouping lines based on path completion and closed contour search.\par
\setlength{\parindent}{2ex}The aforementioned shape-based methods seem to have a good performance in rural scenes with low density of buildings. However, there are some limitations of these methods. Firstly, the shape-based methods inherently limited to handle buildings of arbitrary shape. Secondly, these methods may failed to deal with complicated cases e.g. buildings are close to each other, which thereby is difficult to adapt to today's applications. Thirdly, the method based on shadow to verify corners and calculate height is greatly limited by obvious shadow and sparse building environment. \par
\setlength{\parindent}{2ex}Later, some energy-based methods have been applied to automatic rooftop extraction. Cote \cite{IEEEexample:cote2013automatic} employed corner detection as initial rooftop estimates, and refined with level set evolution. Peng and Liu \cite{IEEEexample:peng2005improved} proposed an approach that segments remote sensing images into high objects, ground and shadow regions, with further refined by an improved snake model. The urban-region-detection problems were casted as one of multiple subgraph matching by Sirmacek et al \cite{IEEEexample:sirmacek2009urban}. They considered each SIFT keypoint as a vertex, neighborhood between different vertex as edge of the graph and formulated the problem of building detection in terms of graph cut.\par
\setlength{\parindent}{2ex}Over the past decade, CNNs have achieved great success in the field of computer vision. There are significant amount of efforts on semantic pixel-level classification for extraction buildings in remote sensing imagery. Mnih \cite{IEEEexample:mnih2013machine} proposed a shallow patch-based network which has only five layers. The input to the model was a 64 by 64 aerial image patch and the output of the network was processed by conditional random fields (CRFs). Satio et al.\cite{IEEEexample:saito2016multiple} applied two major strategies to improve the performance of the network proposed by Mnih. One was a channel-wise inhibited softmax (CIS) for getting a multi-label prediction result, the other was model averaging with spatial displacement (MA) for enhancing the prediction result. Alshehhi et al. \cite{IEEEexample:alshehhi2017simultaneous} adjusted the architecture of network proposed by Mnih through changing the kernel size of convolutional layers and replacing the fully connection layer of the last layer with the average pooling layer. Alternative post-processing stages such as CRFs and multi-scales were used to improve the final result. Some methods took advantage of the feature extraction capability of CNNs to generate feature descriptions of patches. Paisitkriangkrai et al. \cite{IEEEexample:paisitkriangkrai2015effective} made use of both the CNN and hand-craft features extraction,which were combined together to generate final predicted labels of each patch. They also used CRFs as post-processing to get a sound result. Zhao et al. \cite{IEEEexample:zhao2017contextually} proposed a method using edge information of VHR to guide semantic segmentation which combined by CNN-based deep features and semantic-free segments. Unlike Paisitkriangkrai, \cite{IEEEexample:he2017multi} proposed a multi-label pixelwise classification method using the feature vector extracted by a CNN to train a Support Vector Machine (SVM) for classification.\par
\setlength{\parindent}{2ex}More recently, Long \cite{IEEEexample:Long_2015_CVPR} illustrated that Fully Convolutional Networks (FCN) could better handle the problem of multi-label pixel-wise classification. By up-sampling, final predicted result could be the same resolution of the input. Liu et al. \cite{IEEEexample:liu2017dense} did a further research on the formulation proposed by Paisitkriangkrai \cite{IEEEexample:paisitkriangkrai2015effective} but used FCN as the branch of CNN and applied a higher-order CRFs as post-processing. Unlike traditional CRFs, the label consistency for the pixels within the same segment were enforced by higher-order CRFs. SegNet \cite{IEEEexample:badrinarayanan2017segnet} delivered pooling indices computed in the max-pooling to the decoder. It eliminated the need of learning during the up-sample stage while achieving good segmentation performance. The SegNet architecture was used by Audebert et al. \cite{IEEEexample:audebert2017deep} for semantic labeling of remote sensing and got better prediction result compared to the traditional methods. Kampffmeyer at al. \cite{IEEEexample:kampffmeyer2017urban} proposed a novel idea that using CNN with missing data for urban land cover classification. Its idea came from a modality hallucination architecture proposed by Hoffman et al. \cite{IEEEexample:hoffman2016learning} which learned with side information during training stage.\par

Although above-mentioned CNN-based models have exceeded the traditional methods significantly, all of them lost some important hierarchical features extracted from shallow layers of CNNs. These methods usually apply the CNN features from the last layer to get a segmentation result. It is possible to omit tiny objects during the process of pooling, and could not handle the situation when the size of buildings have great difference in distribution. Aiming at this case, a hierarchically fused fully convolutional network is proposed to combine CNN features extracted form each convolutional layer to capture detailed information of input. We will show the details of our paper below. 