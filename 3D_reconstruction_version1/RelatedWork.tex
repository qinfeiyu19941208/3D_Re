\section{Related Work}
\label{Sec:RelatedWork}


Building extraction is one of the most fundamental problems in remote sensing domain, which has been studied for nearly 30 years. 
As time goes by, many research achievements have sprung up. 
We roughly divide these methods into three groups: one is based on the shape prior, another is based on the energy function and machine learning third. 
Here we briefly review some representative methods that have evolved in the past decades in the different groups respectively.
\cxj{More related work on city modeling/urban modeling. Maybe facade modeling.}



During early days, methods are mainly based on the hypothesis of prior knowledge.
Huertas and Nevatia \cite{IEEEexample:huertas1988detecting} assumed that buildings are rectangular or composed of rectangular components.
Based on this, the approach detected lines and corners, traced object boundaries and used shadows to verify. 
Later, a system \cite{IEEEexample:noronha2001detection} for building detection and modelling was proposed with the assumption that the roofs were flat or symmetrical and walls were vertical. 
Using known ground height and detected rooftop, the reconstructed models could be soon obtained. 
Further, Noronha and Nosrati \cite{IEEEexample:nosrati2009novel} transformed the line and intersection points of the image into a graph presentation, and turned the problem of polygon finding into the one that finding loops in the graph. 
However, it was still estimated on assumption that the buildings are polygonal. 
In addition, Izadi and Saeedi\cite{IEEEexample:izadi2012three} presented a complete system for building detection and modelling. 
In the stage of building detection, a tree consisting of intersection points of lines was created and refined based on the found hypotheses. 
The sun azimuth and elevation angles were used to estimate the height with existing shadows afterwards. 
As the height of buildings estimated, the three-dimensional polygonal building models were built. 
In recent years, very high resolution (VHR) optical satellite imagery could be obtained easily. 
Hence, Wang et al~\cite{IEEEexample:wang2015efficient} proposed an efficient method for automatic rectangular building extraction from VHR remote sensing images by detecting line segments and grouping lines based on path integrity and closed contour search.
\cxj{If there are two authors, say A and B proposed.... if more than two authors, say A et al. ..}


The aforementioned shape-based methods have a good performance in rural scenes with low density of buildings. 
Neverthless, there are several limitations of these methods.
First, the shape-based methods inherently limited to handle buildings of arbitrary shapes.
Second, they may failed to deal with complicated cases, for instance, buildings are close to each other, which thereby is hard to adapt to today's applications. 
Third, the algorithms using shadows to verify corners and estimate height are greatly limited to obvious shadows and sparse building environment.


Later, several energy-based methods in image segmentation domain have been applied in automatic rooftop extraction. 
Cote and Saeedi\cite{IEEEexample:cote2013automatic} employed corner detection as an initial estimate of the roof, and then refined with level set evolution. 
Peng et al~\cite{IEEEexample:peng2005improved} proposed an approach that segments remote sensing images into high objects, ground and shadow regions, with further refined by an improved snake model. 
The urban-region-detection problems were casted as one of multiple subgraph matching by Sirmacek and Unsalan\cite{IEEEexample:sirmacek2009urban}. 
They considered each SIFT keypoint as a vertex, neighborhood between vertexs as edge of the graph and formulated the problem of building detection in terms of graph cut.


Over the past decade, CNNs have achieved great success in the field of computer vision. 
There are significant amount of efforts on semantic pixel-level classification for extraction buildings in remote sensing. 
A shallow patch-based network was proposed by Mnih \cite{IEEEexample:mnih2013machine} which has only five layers with a 64 by 64 aerial patch as input. 
And the output of the network was processed by conditional random fields (CRFs). 
Afterwards, Satio et al. \cite{IEEEexample:saito2016multiple} applied two major strategies to improve the performance of the network. 
One was a channel-wise inhibited softmax (CIS) for getting a multi-label prediction result, the other was model averaging with spatial displacement (MA) for enhancing the prediction result. Alshehhi et al. \cite{IEEEexample:alshehhi2017simultaneous} also adjusted the architecture of network proposed by Mnih through changing the kernel size of convolutional layers and replacing the fully connection layer of the last layer with the average pooling layer. Alternative post-processing strategies such as CRFs and multi-scales were used to improve the final prediction results. Some methods took advantage of the feature extraction capability of CNNs to generate feature descriptions of patches. Paisitkriangkrai et al. \cite{IEEEexample:paisitkriangkrai2015effective} made use of both the CNN and hand-craft extracted features, which were combined together to generate predicted labels of each patch. They also used CRFs as post-processing to get a sound result. Zhao et al. \cite{IEEEexample:zhao2017contextually} proposed a method using edge information of VHR to guide semantic segmentation. Unlike \cite{IEEEexample:paisitkriangkrai2015effective}, \cite{IEEEexample:he2017multi} put forward a multi-label pixelwise classification method using the feature vector extracted by a CNN to train a Support Vector Machine (SVM) for classification.


More recently, Long et al. \cite{IEEEexample:Long_2015_CVPR} illustrated that Fully Convolutional Networks (FCN) could better handle the problem of multi-label pixel-wise classification. By up-sampling, final predicted result could be the same resolution of the input. Liu et al. \cite{IEEEexample:liu2017dense} did a further research on the formulation proposed by Paisitkriangkrai \cite{IEEEexample:paisitkriangkrai2015effective} but used FCN as the branch of CNN and applied a higher-order CRFs as post-processing. Unlike traditional CRFs, the label consistency for the pixels within the same segment were enforced by higher-order CRFs. In order to reduce the information loss during pooling stage, SegNet \cite{IEEEexample:badrinarayanan2017segnet} delivered pooling indices computed in the max-pooling to the decoder. It eliminated the need of learning during the up-sample stage while achieving good segmentation performance. The SegNet architecture was used by Audebert et al. \cite{IEEEexample:audebert2017deep} for semantic labeling of remote sensing and got better prediction results compared to the traditional methods. Later, Kampffmeyer at al. \cite{IEEEexample:kampffmeyer2017urban} proposed a novel idea that using CNN with missing data for urban land cover classification. The idea came from a modality hallucination architecture proposed by Hoffman et al. \cite{IEEEexample:hoffman2016learning} which learned with side information during training stage.


In the filed of computer vision, the FCNs \cite{IEEEexample:Long_2015_CVPR} were introduced as a powerful method for semantic segmentation and have achieved great performance. But, along with the deepening of network, the feature maps with lower resolution which causes the segmentation accuracy decline. In order to weaken the influence caused by pooling, Chen et al.\cite{IEEEexample:chen2016deeplab} proposed a atrous convolution which enlarged the receptive field and reduced the number of pooling layers at the same time. Vemulapalli et al.\cite{IEEEexample:vemulapalli2016gaussian} later extended the Deeplab \cite{IEEEexample:chen2016deeplab} with a pairwise network and proposed a Gaussian Conditional Random Field Network for more continuous segmentation results. Afterwards, with the advent of the powerful networks such as ResNet\cite{IEEEexample:he2016deep}, GoogLeNet\cite{IEEEexample:szegedy2015going} and their variants \cite{IEEEexample:szegedy2016rethinking}\cite{IEEEexample:szegedy2017inception}\cite{IEEEexample:xie2017aggregated}, a large amount of literature made use of these networks as their backbone for semantic segmentation. Zhao et al.\cite{IEEEexample:zhao2017contextually} recently developed a pyramid pooling module following the ResNet\cite{IEEEexample:he2016deep} to get multi-scale feature maps and connected these feature maps with those which before pyramid pooling to create the final prediction. Zuo et al.\cite{IEEEexample:zuo2016hf} described a hierarchically fused fully convolutional network, which combined the feature maps from each group of VGG16 Net to generate the final prediction. In this paper, we extend the work of\cite{IEEEexample:zuo2016hf} to explore the effect of different layers of features on the final result. And comparing with other mainstream semantic segmentation networks to prove our method more suitable to the building detection task.


\cxj{Need a paragraph to discuss recent semantic segmentation networks. }

\cxj{Also cite our accv paper and describe the relationship/difference of this journal paper with it.}

Although above-mentioned CNN-based models have exceeded the traditional methods significantly, all of them lost important hierarchical features encoded in the CNNs. They usually apply the CNN features from the last layer to get a segmentation result. It may omit tiny objects during the process of pooling, and could not handle the situation when the size of buildings have great difference in distribution. Aiming at this case, a hierarchical fusion operation is proposed to combine features extracted from each convolutional layer to capture various information of input images. We will describle the details of our idea below.
